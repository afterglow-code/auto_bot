# daily_global_screener.py
import FinanceDataReader as fdr
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import concurrent.futures
from tqdm import tqdm
import os
import pickle
import time
import random

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore', category=FutureWarning)

# =========================================================
# 1. ë°±í…ŒìŠ¤íŠ¸ config ì„¤ì • ì´ì‹ (ë‚´ë¶€ í†µí•©)
# =========================================================
PARAMS = {
    'STOCK_KR': {
        'NAME': 'í•œêµ­ ê°œë³„ì£¼ ê°€ì† ëª¨ë©˜í…€',
        'LISTING': 'KRX',
        'PASSIVE': {
            'MOMENTUM_SHORT': 60,
            'MOMENTUM_LONG': 120,
            'VOLATILITY_WINDOW': 60,
        },
    },
    'STOCK_US': {
        'NAME': 'ë¯¸êµ­ ì£¼ì‹ ê°€ì† ëª¨ë©˜í…€',
        'LISTING': 'S&P500',
        'PASSIVE': {
            'MOMENTUM_WEIGHTS': (0.3, 0.3, 0.4), # 20ì¼, 60ì¼, 120ì¼ ê°€ì¤‘ì¹˜
        },
    }
}

# =========================================================
# 2. ë°±í…ŒìŠ¤íŠ¸ ìŠ¤ì½”ì–´ë§ ë¡œì§ ì´ì‹ (signals._compute_scores)
# =========================================================
def compute_scores(price_data, strategy_name):
    """
    config.pyì— ì •ì˜ëœ íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œì¥ë³„ ë§ì¶¤í˜• ëª¨ë©˜í…€ ìŠ¤ì½”ì–´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    - US: ì§€ì •ëœ ê¸°ê°„ë³„ ê°€ì¤‘ì¹˜ í•©ì‚° ë°©ì‹
    - KR: ë³€ë™ì„±ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•œ ìœ„í—˜ ì¡°ì • ëª¨ë©˜í…€ ë°©ì‹
    """
    strategy_cfg = PARAMS[strategy_name]
    params = strategy_cfg.get('PASSIVE', {})

    if 'MOMENTUM_WEIGHTS' in params: 
        # ê°€ì¤‘ ëª¨ë©˜í…€ ë°©ì‹ (ë¯¸êµ­ ì‹œì¥)
        w1, w2, w3 = params['MOMENTUM_WEIGHTS']
        scores = (price_data.pct_change(20).fillna(0) * w1) + \
                 (price_data.pct_change(60).fillna(0) * w2) + \
                 (price_data.pct_change(120).fillna(0) * w3)
    else: 
        # ë³€ë™ì„± ì¡°ì ˆ ë°©ì‹ (í•œêµ­ ì‹œì¥)
        daily_rets = price_data.pct_change()
        ret_3m = price_data.pct_change(params['MOMENTUM_SHORT'])
        ret_6m = price_data.pct_change(params['MOMENTUM_LONG'])
        vol_3m = daily_rets.rolling(params['VOLATILITY_WINDOW']).std()
        
        epsilon = 1e-6
        score_3m = ret_3m / (vol_3m + epsilon)
        score_6m = ret_6m / (vol_3m + epsilon)
        scores = (score_3m.fillna(0) * 0.5) + (score_6m.fillna(0) * 0.5)
        
    return scores

def get_last_month_first_day(today):
    first_day_of_current_month = today.replace(day=1)
    last_day_of_last_month = first_day_of_current_month - timedelta(days=1)
    return last_day_of_last_month.replace(day=1)

def fetch_price(args):
    """API ì°¨ë‹¨ ë°©ì§€ìš© ì§€ì—° ë° ì§€ìˆ˜ ë°±ì˜¤í”„ê°€ ì ìš©ëœ ê°€ê²© ìˆ˜ì§‘ê¸°"""
    name, code, start_date, retries = args
    time.sleep(random.uniform(0.01, 0.5)) 
    
    for attempt in range(retries):
        try:
            df = fdr.DataReader(code, start=start_date)
            if not df.empty and len(df) > 120: # 120ì¼(ê°€ì¥ ê¸´ ëª¨ë©˜í…€ ê¸°ê°„) ì´ìƒì˜ ë°ì´í„° í•„ìš”
                return df['Close'].rename(name)
            break
        except Exception:
            if attempt < retries - 1:
                time.sleep(2 ** (attempt + 1))
            else:
                pass 
    return None

# =========================================================
# 3. ë©”ì¸ ë¶„ì„ ì—”ì§„
# =========================================================
def analyze_market(strategy_name):
    cfg = PARAMS[strategy_name]
    print("\n" + "="*80)
    print(f"ğŸš€ [{cfg['NAME']}] ì‹œì¥ ë¶„ì„ ì‹œì‘")
    print("="*80)

    os.makedirs('data', exist_ok=True)
    screener_cache_path = f"data/screener_cache_{strategy_name}.pkl"
    listing_cache_path = f"data/listing_cache_{strategy_name}.pkl"
    
    price_data = None
    universe, sector_map, marcap_map = {}, {}, {}

    # 1. ìƒì¥ ì¢…ëª© ë° ì„¹í„° ì •ë³´ ë¡œë”©
    if os.path.exists(listing_cache_path):
        with open(listing_cache_path, 'rb') as f:
            listing_cache = pickle.load(f)
            if listing_cache.get('date') == datetime.now().date():
                print("ğŸ“¦ ë‹¹ì¼ ìºì‹œëœ ìƒì¥ ì¢…ëª© ì •ë³´ ë¡œë“œ ì¤‘...")
                universe = listing_cache['universe']
                sector_map = listing_cache['sector_map']
                marcap_map = listing_cache.get('marcap_map', {})
    
    if not universe:
        print("â³ ìƒì¥ ì¢…ëª© ë° ë°ì´í„° ìŠ¤í¬ë˜í•‘ ì¤‘...")
        if strategy_name == 'STOCK_KR':
            listing = fdr.StockListing('KRX')
            desc = fdr.StockListing('KRX-DESC')
            listing = pd.merge(listing, desc[['Code', 'Sector']], on='Code', how='left')
            listing = listing.dropna(subset=['Sector'])
            listing = listing[
                (~listing['Name'].str.contains('ê´€ë¦¬|í™˜ê¸°|ìŠ¤íŒ©|ìš°$|ìš°B$|ìš°C$')) & 
                (listing['Marcap'] >= 100000000000) # 1000ì–µ ì´ìƒ ìš°ëŸ‰ì£¼
            ]
            universe = {row['Name']: row['Code'] for _, row in listing.iterrows()}
            sector_map = dict(zip(listing['Name'], listing['Sector']))
            marcap_map = dict(zip(listing['Name'], listing['Marcap']))
            
        elif strategy_name == 'STOCK_US':
            listing = fdr.StockListing('S&P500')
            listing = listing.dropna(subset=['Sector'])
            universe = {row['Symbol']: row['Symbol'] for _, row in listing.iterrows()}
            sector_map = dict(zip(listing['Symbol'], listing['Sector']))
            marcap_map = {symbol: 1 for symbol in listing['Symbol']}
        
        with open(listing_cache_path, 'wb') as f:
            pickle.dump({'date': datetime.now().date(), 'universe': universe, 'sector_map': sector_map, 'marcap_map': marcap_map}, f)
        print("âœ… ì¢…ëª©/ì„¹í„° ì •ë³´ ë¡œë”© ì™„ë£Œ!")

    # 2. ê°€ê²© ë°ì´í„° ë³‘ë ¬ ìˆ˜ì§‘ (Max Workers: 4 ì œí•œìœ¼ë¡œ API ì°¨ë‹¨ íšŒí”¼)
    if os.path.exists(screener_cache_path):
        with open(screener_cache_path, 'rb') as f:
            screener_cache = pickle.load(f)
            if screener_cache.get('date') == datetime.now().date():
                print("ğŸ“¦ ë‹¹ì¼ ìºì‹œëœ ê°€ê²© ë°ì´í„° ë¡œë“œ ì¤‘...")
                price_data = screener_cache['price_data']
    
    if price_data is None:
        print("â³ ì¢…ê°€ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ (API ì°¨ë‹¨ ë°©ì§€ ë”œë ˆì´ ì ìš©)...")
        # ê³„ì‚°ì— í•„ìš”í•œ ìµœëŒ€ ê¸°ê°„(120ì¼)ì— ì—¬ìœ ë¥¼ ë”í•´ ì•½ 200ì¼ ì „ë¶€í„° ìˆ˜ì§‘
        start_date = (datetime.now() - timedelta(days=200)).strftime('%Y-%m-%d')
        
        all_price_data = []
        fetch_args = [(name, code, start_date, 3) for name, code in universe.items()]
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            futures = {executor.submit(fetch_price, arg): arg for arg in fetch_args}
            for future in tqdm(concurrent.futures.as_completed(futures), total=len(fetch_args), desc="ë°ì´í„° ë‹¤ìš´ë¡œë“œ", unit="ì¢…ëª©"):
                result = future.result()
                if result is not None:
                    all_price_data.append(result)
        
        if not all_price_data:
            print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return

        price_data = pd.concat(all_price_data, axis=1).ffill()
        with open(screener_cache_path, 'wb') as f:
            pickle.dump({'date': datetime.now().date(), 'price_data': price_data}, f)

    # 3. ì „ëµë³„ ìŠ¤ì½”ì–´ ê³„ì‚° ì ìš©
    print("â³ ë§ì¶¤í˜• ëª¨ë©˜í…€ ìŠ¤ì½”ì–´ ì—°ì‚° ì¤‘...")
    scores = compute_scores(price_data, strategy_name)
    
    sector_df = pd.DataFrame.from_dict(sector_map, orient='index', columns=['Sector'])
    marcap_df = pd.DataFrame.from_dict(marcap_map, orient='index', columns=['Marcap'])
    
    today = price_data.index[-1]
    last_month_start = get_last_month_first_day(today)
    
    today_scores_date = scores.index[scores.index <= today][-1]
    last_month_scores_date = scores.index[scores.index <= last_month_start][-1]

# ì‹œê°€ì´ì•¡ ê°€ì¤‘ í‰ê·  ì ìš© í•¨ìˆ˜
    def calc_weighted_score(df):
        if df['Marcap'].sum() == 0: 
            return df['score'].mean()
        return np.average(df['score'], weights=df['Marcap'])

    # --- ì—¬ê¸°ì„œë¶€í„° ì•„ë˜ ë¶€ë¶„ìœ¼ë¡œ êµì²´ ---

    # ë‹¹ì›” ë­í‚¹ ê³„ì‚°
    merged_today = pd.concat([scores.loc[today_scores_date].rename('score'), sector_df, marcap_df], axis=1).dropna()
    sector_scores_today = merged_today.groupby('Sector').apply(calc_weighted_score)
    
    # [í•µì‹¬ ìˆ˜ì • ì‚¬í•­] DataFrameìœ¼ë¡œ ë°˜í™˜ë  ê²½ìš° 1ì°¨ì› Seriesë¡œ ê°•ì œ ì••ì¶•
    if isinstance(sector_scores_today, pd.DataFrame):
        sector_scores_today = sector_scores_today.squeeze()
        
    current_ranks = sector_scores_today.rank(ascending=False, method='first')
    
    # ì „ì›” ë­í‚¹ ê³„ì‚°
    merged_last_month = pd.concat([scores.loc[last_month_scores_date].rename('score'), sector_df, marcap_df], axis=1).dropna()
    sector_scores_last_month = merged_last_month.groupby('Sector').apply(calc_weighted_score)
    
    # [í•µì‹¬ ìˆ˜ì • ì‚¬í•­] DataFrameìœ¼ë¡œ ë°˜í™˜ë  ê²½ìš° 1ì°¨ì› Seriesë¡œ ê°•ì œ ì••ì¶•
    if isinstance(sector_scores_last_month, pd.DataFrame):
        sector_scores_last_month = sector_scores_last_month.squeeze()
        
    last_ranks = sector_scores_last_month.rank(ascending=False, method='first')
    
    print("\n--- [ë‹¹ì›” ì „ì²´ ì„¹í„° ìˆœìœ„ Top 10] ---")
    top10 = sector_scores_today.nlargest(10).reset_index()
    top10.columns = ['Sector', 'Weighted Score']
    print(top10.to_string(index=False))

    # 4. ê°€ì† ì„¹í„° ë¡œì§ íŒë³„
    accelerating_sectors = []
    candidate_sectors = current_ranks[(current_ranks >= 3) & (current_ranks <= 5)].index
    
    for sector in candidate_sectors:
        if sector in last_ranks.index:
            rank_change = last_ranks[sector] - current_ranks[sector]
            if rank_change >= 2:
                accelerating_sectors.append({
                    'sector': sector, 
                    'rank': int(current_ranks[sector]), 
                    'prev_rank': int(last_ranks[sector])
                })

    print("\n--- [ê°€ì† ëª¨ë©˜í…€ ë¶„ì„ ê²°ê³¼] ---")
    if accelerating_sectors:
        best_accelerating_sector = sorted(accelerating_sectors, key=lambda x: x['rank'])[0]
        sector_name = best_accelerating_sector['sector']
        prev_rank = best_accelerating_sector['prev_rank']
        current_rank = best_accelerating_sector['rank']
        
        stocks_in_sector = merged_today[merged_today['Sector'] == sector_name]
        top_stock = stocks_in_sector['score'].nlargest(1).index[0]
        
        print(f"> ğŸ“ˆ ìƒìŠ¹ ê°€ì† ì„¹í„°: [{sector_name}] (ì „ì›” {prev_rank}ìœ„ -> ë‹¹ì›” {current_rank}ìœ„)")
        print(f"> ğŸ¥‡ í•´ë‹¹ ì„¹í„° ëŒ€ì¥ì£¼: [{top_stock}]")
    else:
        print("> ğŸ’¤ í˜„ì¬ ê°€ì† ëª¨ë©˜í…€ ì¡°ê±´ì— ë¶€í•©í•˜ëŠ” ì„¹í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    markets_to_analyze = ['STOCK_KR', 'STOCK_US']
    for market in markets_to_analyze:
        analyze_market(market)